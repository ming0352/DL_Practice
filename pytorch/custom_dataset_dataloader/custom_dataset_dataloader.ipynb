{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d0f7a6-4e1e-428b-a6aa-f641c6e4b765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "import torch.utils.data as data\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm, trange\n",
    "from torch.utils.data import random_split, SubsetRandomSampler, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision import models\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65d20d8-6e79-4f06-9483-0013af5c375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Micro French-English Dictinary \n",
    "translate = {\"cane\": \"dog\", \n",
    "             \"cavallo\": \"horse\",\n",
    "             \"elefante\": \"elephant\",\n",
    "             \"farfalla\": \"butterfly\",\n",
    "             \"gallina\": \"chicken\", \n",
    "             \"gatto\": \"cat\", \n",
    "             \"mucca\": \"cow\", \n",
    "             \"pecora\": \"sheep\",\n",
    "             \"ragno\": \"spider\",\n",
    "             \"scoiattolo\": \"squirrel\"\n",
    "            }\n",
    "\n",
    "translate_class2num= {\n",
    "             \"cane\": 0, \n",
    "             \"cavallo\": 1,\n",
    "             \"elefante\": 2,\n",
    "             \"farfalla\": 3,\n",
    "             \"gallina\": 4, \n",
    "             \"gatto\": 5, \n",
    "             \"mucca\": 6, \n",
    "             \"pecora\": 7,\n",
    "             \"ragno\": 8,\n",
    "             \"scoiattolo\": 9\n",
    "            }\n",
    "\n",
    "translate_num2slasseng = {\n",
    "             0: \"dog\", \n",
    "             1: \"horse\",\n",
    "             2: \"elephant\",\n",
    "             3: \"butterfly\",\n",
    "             4: \"chicken\", \n",
    "             5: \"cat\", \n",
    "             6: \"cow\", \n",
    "             7: \"sheep\",\n",
    "             8: \"spider\",\n",
    "             9: \"squirrel\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e4056-5a0d-4f77-aee5-fa9da3013eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"animal10/train/\"\n",
    "batch_size= 64\n",
    "num_epochs= 1\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9999ff67-291d-4d54-beea-d16066a6b738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog 3890\n",
      "horse 2098\n",
      "elephant 1156\n",
      "butterfly 1689\n",
      "chicken 2478\n",
      "cat 1334\n",
      "cow 1492\n",
      "sheep 1456\n",
      "spider 3856\n",
      "squirrel 1489\n"
     ]
    }
   ],
   "source": [
    "classes = translate.keys()\n",
    "\n",
    "for _class in classes:\n",
    "    print(translate[_class], len(os.listdir(path + _class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86aa6c8f-5868-4055-a483-ede88cfb8d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19301 19301\n",
      "Skipped: 1637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    3890\n",
       "8    3532\n",
       "4    2478\n",
       "1    2098\n",
       "6    1492\n",
       "9    1489\n",
       "3    1227\n",
       "5    1226\n",
       "7    1080\n",
       "2     789\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path_list = []\n",
    "img_classes_list = []\n",
    "skiped_list = []\n",
    "for class_ in classes: \n",
    "    for img in os.listdir(path + class_):\n",
    "        if (img[-4:] != \"jpeg\"):\n",
    "            skiped_list.append(img)\n",
    "            continue\n",
    "        img_path = path + class_ + \"/\" + img\n",
    "        img_path_list.append(img_path)\n",
    "        img_classes_list.append(translate_class2num[class_])\n",
    "        \n",
    "print(len(img_path_list), len(img_classes_list))\n",
    "print(\"Skipped:\", len(skiped_list))\n",
    "#and (img[-3:] != \"jpg\")\n",
    "pd.value_counts(img_classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851dbbaa-6f8b-49f7-9d25-1e820850e6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17370 1931\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(img_path_list, img_classes_list, test_size=0.1, random_state=42)\n",
    "print(len(x_train), len(x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c5c374f-60bd-4e95-8b9a-9c90fdc92e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(192),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    \n",
    "    # transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "preprocess_valid = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(192),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "class AnimalsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, imgs_list, class_list, transforms = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.imgs_list = imgs_list\n",
    "        self.class_list = class_list\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "    \n",
    "        image_path = self.imgs_list[index]\n",
    "        input_image = Image.open(image_path)\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(input_image)   \n",
    "\n",
    "        label = torch.from_numpy(np.array(self.class_list[index])).to(torch.int64)\n",
    "        \n",
    "        return image, label    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd937cbd-1fa2-41ef-b1de-b1141aeddc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetDataLoader():\n",
    "    def name(self):\n",
    "        return 'CustomDatasetDataLoader'\n",
    "    def __init__(self, imgs_list, class_list, transforms = None):\n",
    "        # super().__init__()\n",
    "        self.dataset = AnimalsDataset(imgs_list, class_list, transforms)\n",
    "        self.dataloader = torch.utils.data.DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=True)\n",
    "\n",
    "    def load_data(self):\n",
    "        return self.dataloader\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3e37c732-db63-49ee-ba44-5dc55e35d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataLoader(imgs_list, class_list, transforms = None):\n",
    "    data_loader = CustomDatasetDataLoader(imgs_list, class_list, transforms)\n",
    "    print(data_loader.name())\n",
    "    dataloader = data_loader.load_data()\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "195e6ad1-d287-4fe6-97ec-e02dbb6bcd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomDatasetDataLoader\n",
      "CustomDatasetDataLoader\n",
      "272 31\n"
     ]
    }
   ],
   "source": [
    "train_data_loader = CreateDataLoader(x_train, y_train, preprocess)\n",
    "valid_data_loader = CreateDataLoader(x_valid, y_valid, preprocess_valid)\n",
    "print(len(train_data_loader),len(valid_data_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e11dff2-db79-4fb2-8a14-88d988622dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1\n"
     ]
    }
   ],
   "source": [
    "# Iterations number\n",
    "iter_num =  math.ceil(len(train_data_loader) / batch_size)\n",
    "iter_valid_num =  math.ceil(len(valid_data_loader) / batch_size)\n",
    "print(iter_num, iter_valid_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "595cba21-82d8-4179-9dd6-40d5f8e901c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor([0.5108, 0.4829, 0.3989])\n",
    "std = torch.tensor([0.2632, 0.2587, 0.2706])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "505e36bc-faab-437a-8c47-90709f648b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_18_model = models.resnet18(pretrained=True)\n",
    "num_fc_ftr = res_18_model.fc.in_features #获取到fc层的输入\n",
    "res_18_model.fc = nn.Linear(num_fc_ftr, 10)\n",
    "model=res_18_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "770e22c4-4d7b-411d-9b9a-0596d29690f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 64, 112, 112]        9,408\n",
      "├─BatchNorm2d: 1-2                       [-1, 64, 112, 112]        128\n",
      "├─ReLU: 1-3                              [-1, 64, 112, 112]        --\n",
      "├─MaxPool2d: 1-4                         [-1, 64, 56, 56]          --\n",
      "├─Sequential: 1-5                        [-1, 64, 56, 56]          --\n",
      "|    └─BasicBlock: 2-1                   [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 56, 56]          36,864\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 64, 56, 56]          128\n",
      "|    |    └─ReLU: 3-3                    [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-4                  [-1, 64, 56, 56]          36,864\n",
      "|    |    └─BatchNorm2d: 3-5             [-1, 64, 56, 56]          128\n",
      "|    |    └─ReLU: 3-6                    [-1, 64, 56, 56]          --\n",
      "|    └─BasicBlock: 2-2                   [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-7                  [-1, 64, 56, 56]          36,864\n",
      "|    |    └─BatchNorm2d: 3-8             [-1, 64, 56, 56]          128\n",
      "|    |    └─ReLU: 3-9                    [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-10                 [-1, 64, 56, 56]          36,864\n",
      "|    |    └─BatchNorm2d: 3-11            [-1, 64, 56, 56]          128\n",
      "|    |    └─ReLU: 3-12                   [-1, 64, 56, 56]          --\n",
      "├─Sequential: 1-6                        [-1, 128, 28, 28]         --\n",
      "|    └─BasicBlock: 2-3                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 128, 28, 28]         73,728\n",
      "|    |    └─BatchNorm2d: 3-14            [-1, 128, 28, 28]         256\n",
      "|    |    └─ReLU: 3-15                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-16                 [-1, 128, 28, 28]         147,456\n",
      "|    |    └─BatchNorm2d: 3-17            [-1, 128, 28, 28]         256\n",
      "|    |    └─Sequential: 3-18             [-1, 128, 28, 28]         8,448\n",
      "|    |    └─ReLU: 3-19                   [-1, 128, 28, 28]         --\n",
      "|    └─BasicBlock: 2-4                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-20                 [-1, 128, 28, 28]         147,456\n",
      "|    |    └─BatchNorm2d: 3-21            [-1, 128, 28, 28]         256\n",
      "|    |    └─ReLU: 3-22                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-23                 [-1, 128, 28, 28]         147,456\n",
      "|    |    └─BatchNorm2d: 3-24            [-1, 128, 28, 28]         256\n",
      "|    |    └─ReLU: 3-25                   [-1, 128, 28, 28]         --\n",
      "├─Sequential: 1-7                        [-1, 256, 14, 14]         --\n",
      "|    └─BasicBlock: 2-5                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-26                 [-1, 256, 14, 14]         294,912\n",
      "|    |    └─BatchNorm2d: 3-27            [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-28                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-29                 [-1, 256, 14, 14]         589,824\n",
      "|    |    └─BatchNorm2d: 3-30            [-1, 256, 14, 14]         512\n",
      "|    |    └─Sequential: 3-31             [-1, 256, 14, 14]         33,280\n",
      "|    |    └─ReLU: 3-32                   [-1, 256, 14, 14]         --\n",
      "|    └─BasicBlock: 2-6                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-33                 [-1, 256, 14, 14]         589,824\n",
      "|    |    └─BatchNorm2d: 3-34            [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-35                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-36                 [-1, 256, 14, 14]         589,824\n",
      "|    |    └─BatchNorm2d: 3-37            [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-38                   [-1, 256, 14, 14]         --\n",
      "├─Sequential: 1-8                        [-1, 512, 7, 7]           --\n",
      "|    └─BasicBlock: 2-7                   [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-39                 [-1, 512, 7, 7]           1,179,648\n",
      "|    |    └─BatchNorm2d: 3-40            [-1, 512, 7, 7]           1,024\n",
      "|    |    └─ReLU: 3-41                   [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-42                 [-1, 512, 7, 7]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-43            [-1, 512, 7, 7]           1,024\n",
      "|    |    └─Sequential: 3-44             [-1, 512, 7, 7]           132,096\n",
      "|    |    └─ReLU: 3-45                   [-1, 512, 7, 7]           --\n",
      "|    └─BasicBlock: 2-8                   [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-46                 [-1, 512, 7, 7]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-47            [-1, 512, 7, 7]           1,024\n",
      "|    |    └─ReLU: 3-48                   [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-49                 [-1, 512, 7, 7]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-50            [-1, 512, 7, 7]           1,024\n",
      "|    |    └─ReLU: 3-51                   [-1, 512, 7, 7]           --\n",
      "├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --\n",
      "├─Linear: 1-10                           [-1, 10]                  5,130\n",
      "==========================================================================================\n",
      "Total params: 11,181,642\n",
      "Trainable params: 11,181,642\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.84\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 37.90\n",
      "Params size (MB): 42.65\n",
      "Estimated Total Size (MB): 81.13\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv2d: 1-1                            [-1, 64, 112, 112]        9,408\n",
       "├─BatchNorm2d: 1-2                       [-1, 64, 112, 112]        128\n",
       "├─ReLU: 1-3                              [-1, 64, 112, 112]        --\n",
       "├─MaxPool2d: 1-4                         [-1, 64, 56, 56]          --\n",
       "├─Sequential: 1-5                        [-1, 64, 56, 56]          --\n",
       "|    └─BasicBlock: 2-1                   [-1, 64, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 64, 56, 56]          36,864\n",
       "|    |    └─BatchNorm2d: 3-2             [-1, 64, 56, 56]          128\n",
       "|    |    └─ReLU: 3-3                    [-1, 64, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-4                  [-1, 64, 56, 56]          36,864\n",
       "|    |    └─BatchNorm2d: 3-5             [-1, 64, 56, 56]          128\n",
       "|    |    └─ReLU: 3-6                    [-1, 64, 56, 56]          --\n",
       "|    └─BasicBlock: 2-2                   [-1, 64, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-7                  [-1, 64, 56, 56]          36,864\n",
       "|    |    └─BatchNorm2d: 3-8             [-1, 64, 56, 56]          128\n",
       "|    |    └─ReLU: 3-9                    [-1, 64, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-10                 [-1, 64, 56, 56]          36,864\n",
       "|    |    └─BatchNorm2d: 3-11            [-1, 64, 56, 56]          128\n",
       "|    |    └─ReLU: 3-12                   [-1, 64, 56, 56]          --\n",
       "├─Sequential: 1-6                        [-1, 128, 28, 28]         --\n",
       "|    └─BasicBlock: 2-3                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-13                 [-1, 128, 28, 28]         73,728\n",
       "|    |    └─BatchNorm2d: 3-14            [-1, 128, 28, 28]         256\n",
       "|    |    └─ReLU: 3-15                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-16                 [-1, 128, 28, 28]         147,456\n",
       "|    |    └─BatchNorm2d: 3-17            [-1, 128, 28, 28]         256\n",
       "|    |    └─Sequential: 3-18             [-1, 128, 28, 28]         8,448\n",
       "|    |    └─ReLU: 3-19                   [-1, 128, 28, 28]         --\n",
       "|    └─BasicBlock: 2-4                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-20                 [-1, 128, 28, 28]         147,456\n",
       "|    |    └─BatchNorm2d: 3-21            [-1, 128, 28, 28]         256\n",
       "|    |    └─ReLU: 3-22                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-23                 [-1, 128, 28, 28]         147,456\n",
       "|    |    └─BatchNorm2d: 3-24            [-1, 128, 28, 28]         256\n",
       "|    |    └─ReLU: 3-25                   [-1, 128, 28, 28]         --\n",
       "├─Sequential: 1-7                        [-1, 256, 14, 14]         --\n",
       "|    └─BasicBlock: 2-5                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-26                 [-1, 256, 14, 14]         294,912\n",
       "|    |    └─BatchNorm2d: 3-27            [-1, 256, 14, 14]         512\n",
       "|    |    └─ReLU: 3-28                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-29                 [-1, 256, 14, 14]         589,824\n",
       "|    |    └─BatchNorm2d: 3-30            [-1, 256, 14, 14]         512\n",
       "|    |    └─Sequential: 3-31             [-1, 256, 14, 14]         33,280\n",
       "|    |    └─ReLU: 3-32                   [-1, 256, 14, 14]         --\n",
       "|    └─BasicBlock: 2-6                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-33                 [-1, 256, 14, 14]         589,824\n",
       "|    |    └─BatchNorm2d: 3-34            [-1, 256, 14, 14]         512\n",
       "|    |    └─ReLU: 3-35                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-36                 [-1, 256, 14, 14]         589,824\n",
       "|    |    └─BatchNorm2d: 3-37            [-1, 256, 14, 14]         512\n",
       "|    |    └─ReLU: 3-38                   [-1, 256, 14, 14]         --\n",
       "├─Sequential: 1-8                        [-1, 512, 7, 7]           --\n",
       "|    └─BasicBlock: 2-7                   [-1, 512, 7, 7]           --\n",
       "|    |    └─Conv2d: 3-39                 [-1, 512, 7, 7]           1,179,648\n",
       "|    |    └─BatchNorm2d: 3-40            [-1, 512, 7, 7]           1,024\n",
       "|    |    └─ReLU: 3-41                   [-1, 512, 7, 7]           --\n",
       "|    |    └─Conv2d: 3-42                 [-1, 512, 7, 7]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-43            [-1, 512, 7, 7]           1,024\n",
       "|    |    └─Sequential: 3-44             [-1, 512, 7, 7]           132,096\n",
       "|    |    └─ReLU: 3-45                   [-1, 512, 7, 7]           --\n",
       "|    └─BasicBlock: 2-8                   [-1, 512, 7, 7]           --\n",
       "|    |    └─Conv2d: 3-46                 [-1, 512, 7, 7]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-47            [-1, 512, 7, 7]           1,024\n",
       "|    |    └─ReLU: 3-48                   [-1, 512, 7, 7]           --\n",
       "|    |    └─Conv2d: 3-49                 [-1, 512, 7, 7]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-50            [-1, 512, 7, 7]           1,024\n",
       "|    |    └─ReLU: 3-51                   [-1, 512, 7, 7]           --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --\n",
       "├─Linear: 1-10                           [-1, 10]                  5,130\n",
       "==========================================================================================\n",
       "Total params: 11,181,642\n",
       "Trainable params: 11,181,642\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.84\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 37.90\n",
       "Params size (MB): 42.65\n",
       "Estimated Total Size (MB): 81.13\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = MyCustomResnet18()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "04739af3-1c0c-4167-b608-32272351905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute accuracy\n",
    "def get_accuracy(logit, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e463760c-555d-4e70-b1dc-55abd0211e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4b5b2387-c832-4e14-a498-aac9c6b4fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    epoch_acc=0.0\n",
    "    size = len(dataloader.dataset) # number of samples\n",
    "    num_batches = len(dataloader) # batches per epoch\n",
    "\n",
    "    model.train() # Sets the model in training mode.\n",
    "    epoch_loss, epoch_correct = 0, 0\n",
    "\n",
    "    for batch_i, (images, labels) in tqdm(enumerate(dataloader)):\n",
    "        images, labels = images.to(device), labels.to(device) # move data to GPU\n",
    "\n",
    "        # Compute prediction loss\n",
    "        pred = model(images)\n",
    "        loss = criterion(pred, labels)\n",
    "\n",
    "        # Optimization by gradients\n",
    "        optimizer.zero_grad() # set prevision gradient to 0\n",
    "        loss.backward() # backpropagation to compute gradients\n",
    "        optimizer.step() # update model params\n",
    "\n",
    "        # write to logs\n",
    "        #epoch_loss += loss.item()\n",
    "        epoch_loss += loss.detach().item()\n",
    "        # epoch_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        epoch_correct +=(torch.max(pred, 1)[1].view(labels.size()).data == labels.data).sum()\n",
    "        epoch_acc += get_accuracy(pred, labels, batch_size)\n",
    "    \n",
    "    \n",
    "    return epoch_loss/num_batches,epoch_acc/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07567300-9c86-4c44-b1e9-6d98e6b27c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    epoch_acc=0.0\n",
    "    size = len(dataloader.dataset) # number of samples\n",
    "    num_batches = len(dataloader) # batches per epoch\n",
    "\n",
    "    model.eval() # Sets the model in test mode.\n",
    "    epoch_loss, epoch_correct = 0, 0\n",
    "\n",
    "    # No training for test data\n",
    "    with torch.no_grad():\n",
    "        for batch_i, (images, labels) in tqdm(enumerate(dataloader)):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            pred = model(images)\n",
    "            loss = criterion(pred, labels)\n",
    "            \n",
    "            #epoch_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            # epoch_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            epoch_correct+=(torch.max(pred, 1)[1].view(labels.size()).data == labels.data).sum()\n",
    "            epoch_acc += get_accuracy(pred, labels, batch_size)\n",
    "    return epoch_loss/num_batches, epoch_acc/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ab7777f6-b747-4667-ad41-1da016b3931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define draw\n",
    "def plotCurve(x_vals, y_vals, \n",
    "                x_label, y_label, \n",
    "                x2_vals=None, y2_vals=None, \n",
    "                legend=None,\n",
    "                figsize=(3.5, 2.5)):\n",
    "    # set figsize\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.plot(x_vals, y_vals)\n",
    "    # plt.semilogy(x_vals, y_vals)\n",
    "    if x2_vals and y2_vals:\n",
    "        # plt.semilogy(x2_vals, y2_vals, linestyle=':')\n",
    "        plt.plot(x_vals, y2_vals)\n",
    "    if legend:\n",
    "        plt.legend(legend)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8a6474d8-08c2-4aff-beb6-d0b349393cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "272it [01:04,  4.19it/s]\n",
      "31it [00:05,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/1  Training Loss:0.662 || Training Acc 78.194 % ||  valid Loss:0.655 ||  valid Acc 79.335 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(train_data_loader, model, criterion, optimizer)\n",
    "    val_loss, val_acc = test(valid_data_loader, model, criterion)\n",
    "    print(\"Epoch:{}/{}  Training Loss:{:.3f} || Training Acc {:.3f} % ||  valid Loss:{:.3f} ||  valid Acc {:.3f} %\".format(epoch + 1,\n",
    "                                                                                                         num_epochs,\n",
    "                                                                                                         train_loss,\n",
    "                                                                                                         train_acc,                            \n",
    "                                                                                                         val_loss,\n",
    "                                                                                                         val_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
